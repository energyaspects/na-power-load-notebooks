{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTS/REQUIREMENTS\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import holidays\n",
    "import inspect\n",
    "from scipy.optimize import curve_fit\n",
    "from tqdm import tqdm\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from helper_functions_ea import check_env, ShoojuTools\n",
    "check_env()\n",
    "sj = ShoojuTools()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UTILS\n",
    "def get_temp_load_curve(data_coef):\n",
    "    temp_load_curve = data_coef.set_index('temp').sort_index()\n",
    "    temp_load_curve = temp_load_curve.loc[temp_load_curve.workday == temp_load_curve.workday.max(),'load']\n",
    "    temp_range = temp_load_curve.index.max() - temp_load_curve.index.min()\n",
    "    window = int(len(temp_load_curve)/temp_range)\n",
    "    temp_load_curve = temp_load_curve.rolling(window, center=True).mean().dropna()\n",
    "    return temp_load_curve\n",
    "\n",
    "def get_workday(series):\n",
    "    series_idx = pd.Series(series.index, series.index).asfreq('h')\n",
    "    weekend = series_idx.dt.dayofweek >= 5\n",
    "    us_holidays = holidays.US()\n",
    "    holiday = series_idx.apply(lambda x: x.date() in us_holidays)\n",
    "    workday = (~holiday & ~weekend).astype(int)\n",
    "    workday.name = 'workday'\n",
    "    return workday\n",
    "\n",
    "def get_func_params(func):\n",
    "    params = inspect.signature(func).parameters\n",
    "    params = [param_name for param_name, param in params.items()]\n",
    "    if 'xdata' in params:\n",
    "        params.remove('xdata')\n",
    "    return params\n",
    "\n",
    "def get_load_sids_dict():\n",
    "    load_sid_dict = {'ERCOT': fr'teams\\power\\ERCOT\\load\\hourly',\n",
    "                      'PJM': fr'teams\\power\\PJM\\load\\hourly'}\n",
    "    return load_sid_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# METADATA\n",
    "def get_iso_zone_sids(iso_rto, iso_zone):\n",
    "    # REALISED LOAD\n",
    "    query = get_load_sids_dict()[iso_rto] + fr'\\{iso_zone}'\n",
    "    load_sid = sj.get_fields_from_query(query, fields=['sid'])['sid']\n",
    "    load_sid.index = load_sid.str[len(query)-5:]\n",
    "    load_sid.name = 'load_real'\n",
    "\n",
    "    #EA GROWTH FORECAST\n",
    "    query = fr'users\\will.spencer\\power\\models\\load\\growth\\total\\{iso_rto}\\{iso_zone}'\n",
    "    growth_sid = sj.get_fields_from_query(query, fields=['sid'])['sid']\n",
    "    growth_sid.index = growth_sid.str[len(query)-5:]\n",
    "    growth_sid.name = 'growth_total'\n",
    "\n",
    "    # REALISED HDD'S AND CDD'S\n",
    "    if iso_zone == iso_rto:\n",
    "        query = fr'sid:teams\\weather\\spire\\us_POWER_{iso_rto} unit=C'\n",
    "    else:\n",
    "        query = fr'sid:teams\\weather\\spire\\us_POWER_{iso_rto}_{iso_zone} unit=C'\n",
    "    real_degree_sid = sj.get_fields_from_query(query, fields=['sid'])['sid']\n",
    "    real_degree_sid.index = real_degree_sid.str[len(query)-16:-4].replace('', iso_rto)\n",
    "    hdd_real_sid = real_degree_sid.loc[real_degree_sid.str.lower().str.contains('hdd')]\n",
    "    hdd_real_sid.name = 'hdd_real'\n",
    "    cdd_real_sid = real_degree_sid.loc[real_degree_sid.str.lower().str.contains('cdd')]\n",
    "    cdd_real_sid.name = 'cdd_real'\n",
    "\n",
    "    # NORMAL HDD'S AND CDD'S\n",
    "    if iso_zone == iso_rto:\n",
    "        query = fr'sid:Spire\\weather\\10yr_normal\\NA\\US\\POWER_{iso_rto} unit=C'\n",
    "    else:\n",
    "        query = fr'sid:Spire\\weather\\10yr_normal\\NA\\US\\POWER_{iso_rto}_{iso_zone} unit=C'\n",
    "\n",
    "    norm_degree_sid = sj.get_fields_from_query(query, fields=['sid'])['sid']\n",
    "    norm_degree_sid.index = norm_degree_sid.str[len(query)-16:-6].replace('', iso_rto)\n",
    "    hdd_norm_sid = norm_degree_sid.loc[norm_degree_sid.str.lower().str.contains('hdd')]\n",
    "    hdd_norm_sid.name = 'hdd_norm'\n",
    "    cdd_norm_sid = norm_degree_sid.loc[norm_degree_sid.str.lower().str.contains('cdd')]\n",
    "    cdd_norm_sid.name = 'cdd_norm'\n",
    "\n",
    "    # CONCAT AND CHECK ALL DATA EXISTS\n",
    "    iso_zone_sids = pd.concat([load_sid, growth_sid, hdd_real_sid, cdd_real_sid, hdd_norm_sid, cdd_norm_sid], axis=1).dropna()\n",
    "    if len(iso_zone_sids)>0:\n",
    "        iso_zone_sids = iso_zone_sids.iloc[0]\n",
    "        sids_exist = True\n",
    "    else:\n",
    "        sids_exist = False\n",
    "\n",
    "    return sids_exist, iso_zone_sids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXTRACTORS\n",
    "def get_temp_real(iso_zone_sids):\n",
    "    cdd_real = sj.get_points_from_sid_into_series(iso_zone_sids.cdd_real, date_start=\"MIN\", date_finish=\"MAX\")\n",
    "    hdd_real = sj.get_points_from_sid_into_series(iso_zone_sids.hdd_real, date_start=\"MIN\", date_finish=\"MAX\")\n",
    "    temp_real = cdd_real-hdd_real+18\n",
    "    temp_real = temp_real.asfreq('H').ffill()\n",
    "    temp_real.name = 'temp'\n",
    "    return temp_real\n",
    "\n",
    "def get_temp_norm(iso_zone_sids, data):\n",
    "    cdd_norm = sj.get_points_from_sid_into_series(iso_zone_sids.cdd_norm, date_start=\"MIN\", date_finish=\"MAX\")\n",
    "    hdd_norm = sj.get_points_from_sid_into_series(iso_zone_sids.hdd_norm, date_start=\"MIN\", date_finish=\"MAX\")\n",
    "    temp_norm = cdd_norm-hdd_norm+18\n",
    "    temp_norm.index = temp_norm.index.dayofyear\n",
    "    temp_norm = temp_norm.groupby(level=0).agg(pd.Series.mode)\n",
    "    \n",
    "    norm_start = data['temp_real'].index.min()\n",
    "    norm_end = data['growth_total'].index.max() + pd.offsets.YearEnd()\n",
    "    norm_date_range = pd.date_range(norm_start, norm_end, freq='H')\n",
    "\n",
    "    temp_norm = norm_date_range.day_of_year.map(temp_norm)\n",
    "    temp_norm = pd.Series(temp_norm, norm_date_range)\n",
    "    temp_norm.name = 'temp'\n",
    "    return temp_norm\n",
    "\n",
    "def get_load_real(iso_zone_sids):\n",
    "    load_real = sj.get_points_from_sid_into_series(iso_zone_sids.load_real, date_start=\"MIN\", date_finish=\"MAX\")\n",
    "    load_real.name = 'load'\n",
    "    return load_real\n",
    "\n",
    "def get_growth_total(iso_zone_sids):\n",
    "    growth_total = sj.get_points_from_sid_into_series(iso_zone_sids.growth_total, date_start=\"MIN\", date_finish=\"MAX\")\n",
    "    growth_total.name = 'growth_total'\n",
    "    return growth_total\n",
    "\n",
    "def get_data(iso_zone_sids):\n",
    "    data = {'temp_real':get_temp_real(iso_zone_sids),\n",
    "            'load_real':get_load_real(iso_zone_sids),\n",
    "            'growth_total': get_growth_total(iso_zone_sids)}\n",
    "    data['temp_norm'] = get_temp_norm(iso_zone_sids, data)\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL DATA\n",
    "\n",
    "# rolling (DAILY) MODEL\n",
    "def get_data_coef(data):\n",
    "    data_coef = pd.concat([data['load_real'], data['temp_real']], axis=1).dropna()\n",
    "    data_coef['workday'] = get_workday(data_coef)\n",
    "    data_coef = data_coef.asfreq('H').rolling(24, center=True).mean().dropna()\n",
    "    return data_coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD MODEL FUNCS\n",
    "\n",
    "def base_load_coefs_func(xdata, base_demand, workday_demand):\n",
    "    base_load = base_demand + workday_demand*xdata.workday\n",
    "    return base_load\n",
    "\n",
    "def heat_load_coefs_func(xdata, util_temp_max, heat_util_mask, heat_demand):\n",
    "    heat_load = (heat_demand)*(util_temp_max-xdata.temp)*heat_util_mask\n",
    "    return heat_load\n",
    "\n",
    "def cool_load_coefs_func(xdata, util_temp_min, cool_util_mask, cool_demand):\n",
    "    cool_load = (cool_demand)*(xdata.temp-util_temp_min)*cool_util_mask\n",
    "    return cool_load\n",
    "\n",
    "def util_func(xdata, util_temp_min, util_temp_max):\n",
    "    heat_util_mask = (xdata.temp - util_temp_max)/(util_temp_min-util_temp_max)\n",
    "    heat_util_mask.loc[xdata.temp<util_temp_min] = 1\n",
    "    heat_util_mask.loc[xdata.temp>util_temp_max] = 0\n",
    "\n",
    "    cool_util_mask = (util_temp_min-xdata.temp)/(util_temp_min-util_temp_max)\n",
    "    cool_util_mask.loc[xdata.temp>util_temp_max] = 1\n",
    "    cool_util_mask.loc[xdata.temp<util_temp_min] = 0\n",
    "\n",
    "    return heat_util_mask, cool_util_mask\n",
    "\n",
    "def load_coefs_func(xdata, base_demand, workday_demand, heat_demand, cool_demand, util_temp_min, util_temp_max):\n",
    "\n",
    "    base_load = base_load_coefs_func(xdata, base_demand, workday_demand)\n",
    "    heat_util_mask, cool_util_mask = util_func(xdata, util_temp_min, util_temp_max)\n",
    "\n",
    "    heat_load = heat_load_coefs_func(xdata, util_temp_max, heat_util_mask, heat_demand)\n",
    "    cool_load = cool_load_coefs_func(xdata, util_temp_min, cool_util_mask, cool_demand)\n",
    "\n",
    "    load = base_load + heat_load + cool_load\n",
    "    return load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GET DATE TO FIT INITIAL LOAD MODEL COEFS\n",
    "def get_coef_init_date(data_coef):\n",
    "    temp_load_min = get_temp_load_curve(data_coef).idxmin()\n",
    "\n",
    "    heat_start_date = (data_coef.temp > temp_load_min).groupby(pd.Grouper(freq='W')).mean()\n",
    "    heat_start_date = heat_start_date[heat_start_date == 1].index.min()\n",
    "\n",
    "    cool_start_date = (data_coef.temp < temp_load_min).groupby(pd.Grouper(freq='W')).mean()\n",
    "    cool_start_date = cool_start_date[cool_start_date == 1].index.min()\n",
    "\n",
    "    coef_init_date = max(heat_start_date, cool_start_date)\n",
    "    coef_init_date = coef_init_date + pd.offsets.MonthBegin(2)\n",
    "    return coef_init_date\n",
    "\n",
    "# INITIAL bounding\n",
    "def get_init_bounds(coef_init_data):\n",
    "    init_curve = get_temp_load_curve(coef_init_data)\n",
    "    temp_min = init_curve.index.min()\n",
    "    temp_max = init_curve.index.max()\n",
    "    curve_min = init_curve.idxmin()\n",
    "    load_min = init_curve.min()\n",
    "\n",
    "    init_bounds = {'base_demand':{'lower': 0,\n",
    "                                  'upper': load_min},\n",
    "                   'workday_demand':{'lower': 0,\n",
    "                                  'upper': load_min},\n",
    "                   'heat_demand':{'lower': 0,\n",
    "                                  'upper': np.inf},\n",
    "                   'cool_demand':{'lower': 0,\n",
    "                                  'upper': np.inf},\n",
    "                   'util_temp_min':{'lower': temp_min,\n",
    "                                    'upper': curve_min},\n",
    "                   'util_temp_max':{'lower': curve_min,\n",
    "                                    'upper': temp_max}}\n",
    "\n",
    "    init_bounds = pd.DataFrame(init_bounds).transpose()\n",
    "    init_bounds = (init_bounds.lower.to_list(), init_bounds.upper.to_list())\n",
    "    return init_bounds\n",
    "\n",
    "# INITIAL COEF PARAMETERS\n",
    "def fit_start_params(data_coef, init_date, init_bounds):\n",
    "    xdata = data_coef.loc[:init_date, data_coef.columns.drop('load')]\n",
    "    ydata = data_coef.loc[:init_date, 'load']\n",
    "    popt, pcov = curve_fit(load_coefs_func, xdata, ydata, bounds=init_bounds)\n",
    "    perr = np.sqrt(np.diag(pcov))\n",
    "\n",
    "    params = get_func_params(load_coefs_func)\n",
    "    start_params = pd.DataFrame([popt-3*perr, popt, popt+3*perr], ['lower','coef','upper'], params)\n",
    "    start_params = start_params.transpose()\n",
    "    return start_params\n",
    "\n",
    "# BOOTSTRAP DATA FOR GIVEN DATE\n",
    "def bootstrap_fit_data(data, fit_date, params):\n",
    "    trailing = data.loc[fit_date - pd.DateOffset(28):fit_date]\n",
    "    trailing = trailing.loc[trailing.load > params.lower.base_demand]\n",
    "    leading = data.loc[fit_date:fit_date + pd.DateOffset(28)]\n",
    "    leading = leading.loc[leading.load > params.lower.base_demand]\n",
    "\n",
    "    if len(trailing)>0 and len(leading) > 0:\n",
    "        trailing = trailing.iloc[np.random.randint(0, len(trailing), 1000)]\n",
    "        leading = leading.iloc[np.random.randint(0, len(leading), 1000)]\n",
    "        fit_data = pd.concat([trailing, leading]).reset_index(drop=True)\n",
    "        \n",
    "    else:\n",
    "        fit_data = pd.DataFrame()\n",
    "    \n",
    "    return fit_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIT WEEKLY DATA\n",
    "def fit_load_wrap(fit_data, wrap, params, scale_params):\n",
    "    xdata = fit_data.drop(columns='load')\n",
    "    ydata = fit_data.load\n",
    "\n",
    "    fit_params = get_func_params(wrap)\n",
    "    if len(scale_params) > 0: params.loc['scale'] = [-np.inf,1,np.inf]\n",
    "\n",
    "    lower = params.loc[fit_params, 'lower'].to_list()\n",
    "    p0 = params.loc[fit_params, 'coef'].to_list()\n",
    "    upper = params.loc[fit_params, 'upper'].to_list()\n",
    "    bounds = (lower, upper)\n",
    "\n",
    "    popt, pcov = curve_fit(wrap, xdata, ydata, p0=p0, bounds=bounds)\n",
    "    perr = np.sqrt(np.diag(pcov))\n",
    "    params.loc[fit_params, 'lower'] = popt - 3*perr\n",
    "    params.loc[fit_params, 'coef'] = popt\n",
    "    params.loc[fit_params, 'upper'] = popt + 3*perr\n",
    "\n",
    "    if len(scale_params) > 0: \n",
    "        params.loc[scale_params] = params.loc[scale_params]*params.coef.scale\n",
    "        params = params.drop('scale')\n",
    "\n",
    "    return params\n",
    "\n",
    "# WEEKLY FIT TYPES\n",
    "# HEAT\n",
    "def fit_heat_params(fit_data, params):\n",
    "    def load_wrap(xdata, base_demand, workday_demand, heat_demand, util_temp_min):\n",
    "        load = load_coefs_func(xdata, \n",
    "                        base_demand, workday_demand, \n",
    "                        heat_demand, params.coef.cool_demand, \n",
    "                        util_temp_min, params.coef.util_temp_max)\n",
    "        return load\n",
    "    scale_params = []\n",
    "    params = fit_load_wrap(fit_data, load_wrap, params, scale_params)\n",
    "\n",
    "    return params\n",
    "\n",
    "def fit_cool_params(fit_data, params):\n",
    "    def load_wrap(xdata, base_demand, workday_demand, cool_demand, util_temp_max):\n",
    "        load = load_coefs_func(xdata, \n",
    "                        base_demand, workday_demand, \n",
    "                        params.coef.heat_demand, cool_demand, \n",
    "                        params.coef.util_temp_min, util_temp_max)\n",
    "        return load\n",
    "    scale_params = []\n",
    "    params = fit_load_wrap(fit_data, load_wrap, params, scale_params)\n",
    "\n",
    "    return params\n",
    "\n",
    "def fit_base_params(fit_data, params):\n",
    "    def load_wrap(xdata, base_demand, workday_demand, scale):\n",
    "        load = load_coefs_func(xdata, \n",
    "                        base_demand, workday_demand, \n",
    "                        scale*params.coef.heat_demand, scale*params.coef.cool_demand, \n",
    "                        params.coef.util_temp_min, params.coef.util_temp_max)\n",
    "        return load\n",
    "    scale_params = ['heat_demand', 'cool_demand']\n",
    "    params = fit_load_wrap(fit_data, load_wrap, params, scale_params)\n",
    "\n",
    "    return params\n",
    "\n",
    "def scale_params(fit_data, params):\n",
    "    def load_wrap(xdata, scale):\n",
    "        load = load_coefs_func(xdata, \n",
    "                        scale*params.coef.base_demand, scale*params.coef.workday_demand, \n",
    "                        scale*params.coef.heat_demand, scale*params.coef.cool_demand, \n",
    "                        params.coef.util_temp_min, params.coef.util_temp_max)\n",
    "        return load\n",
    "    scale_params = ['base_demand', 'workday_demand', 'heat_demand', 'cool_demand']\n",
    "    params = fit_load_wrap(fit_data, load_wrap, params, scale_params)\n",
    "\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DETERMINE WHICH PART OF CURVE SHOULD BE FIT AND FIT IT\n",
    "def fit_date_coefs(fit_data, params):\n",
    "    if len(fit_data)>0:\n",
    "\n",
    "        heat_mask = fit_data.temp <= params.coef.util_temp_min\n",
    "        cool_mask = fit_data.temp >= params.coef.util_temp_max\n",
    "\n",
    "        fit_heat = heat_mask.mean() > 0.5\n",
    "        fit_cool = cool_mask.mean() > 0.5\n",
    "        fit_util = heat_mask.sum() > 0 and cool_mask.sum() > 0       \n",
    "    else:\n",
    "        return params\n",
    "    \n",
    "    if fit_heat and fit_util: return fit_heat_params(fit_data, params)\n",
    "    elif fit_cool and fit_util: return fit_cool_params(fit_data, params)\n",
    "    elif fit_util: return fit_base_params(fit_data, params)\n",
    "    else: return scale_params(fit_data, params)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_coefs(data):\n",
    "    coefs = dict()\n",
    "    data_coef = get_data_coef(data)\n",
    "    init_date = get_coef_init_date(data_coef)\n",
    "    init_bounds = get_init_bounds(data_coef.loc[:init_date])\n",
    "    params = fit_start_params(data_coef, init_date, init_bounds)\n",
    "\n",
    "    coef_date_range = pd.date_range(init_date, data_coef.index.max(), freq='W')\n",
    "    for fit_date in (coef_date_range):\n",
    "        fit_data = bootstrap_fit_data(data_coef, fit_date, params)\n",
    "        params = fit_date_coefs(fit_data, params)\n",
    "        coefs[fit_date] = params.coef.copy()\n",
    "\n",
    "    coefs = pd.DataFrame(coefs).transpose()\n",
    "    return coefs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_xdata_coef(temp):\n",
    "    xdata = pd.DataFrame(temp)\n",
    "    xdata['workday'] = get_workday(xdata)\n",
    "    xdata = xdata.asfreq('H').rolling(24, center=True).mean().dropna()\n",
    "    return xdata\n",
    "\n",
    "def get_load_coefs(temp, coefs):\n",
    "    load_coefs = pd.Series(dtype='float')\n",
    "    xdata_coef = get_xdata_coef(temp)\n",
    "    coef_date_range = coefs.index\n",
    "    for pred_date in coef_date_range:\n",
    "        xdata = xdata_coef.loc[pred_date-pd.DateOffset(28):pred_date+pd.DateOffset(28)]\n",
    "        load_coefs = pd.concat([load_coefs, load_coefs_func(xdata, *coefs.loc[pred_date])])\n",
    "    load_coefs = load_coefs.groupby(level=0).mean()\n",
    "    load_coefs.name = 'load'\n",
    "\n",
    "    return load_coefs\n",
    "\n",
    "def get_data_hour(data, coefs):\n",
    "    load_pred = get_load_coefs(data['temp_real'], coefs)\n",
    "    load_real = data['load_real'].copy()\n",
    "    load_err = pd.Series(load_pred/load_real, name = 'load_err')\n",
    "    data_hour = pd.concat([load_real, load_err], axis=1).dropna()\n",
    "    \n",
    "    return data_hour\n",
    "\n",
    "def fit_hour_adj(data, coefs):\n",
    "    hour_adj = dict()\n",
    "    data_hour = get_data_hour(data, coefs)\n",
    "    coef_date_range = coefs.index\n",
    "    for fit_date in coef_date_range:\n",
    "        fit_data = data_hour.loc[fit_date-pd.DateOffset(28):fit_date+pd.DateOffset(28)].dropna()\n",
    "        load_loss = coefs.loc[fit_date,'base_demand'] - 3*fit_data.load.std()\n",
    "        fit_data = fit_data.loc[fit_data.load > load_loss, 'load_err']\n",
    "        hour_adj[fit_date] = fit_data.groupby(fit_data.index.hour).mean()\n",
    "\n",
    "    hour_adj = pd.DataFrame(hour_adj).transpose()\n",
    "    return hour_adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_load_model(temp, coefs, hour_adj):\n",
    "    xdata_coef = get_xdata_coef(temp)\n",
    "    load = pd.Series(dtype='float')\n",
    "    pred_date_range = pd.concat([coefs, hour_adj], axis=1).index\n",
    "    for pred_date in pred_date_range:\n",
    "        pred_data = xdata_coef.loc[pred_date-pd.DateOffset(28):pred_date+pd.DateOffset(28)].dropna()\n",
    "        pred_date_load = load_coefs_func(pred_data, *coefs.loc[pred_date])\n",
    "        pred_date_load = pred_date_load*pred_date_load.index.hour.map(hour_adj.loc[pred_date])\n",
    "        load = pd.concat([load, pred_date_load])\n",
    "    load = load.groupby(level=0).mean()\n",
    "\n",
    "    return load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_forecast_growth_adj(data, date_range):\n",
    "    growth_rate = (1 + data['growth_total'])**(1/8760)\n",
    "    growth_rate = growth_rate.reindex(date_range).bfill().ffill()\n",
    "\n",
    "    forecast_growth_adj = dict()\n",
    "\n",
    "    growth_factor = 1\n",
    "    for growth_date in date_range:\n",
    "        growth_factor = growth_factor*growth_rate.loc[growth_date]\n",
    "        forecast_growth_adj[growth_date] = growth_factor\n",
    "\n",
    "    forecast_growth_adj = pd.Series(forecast_growth_adj)\n",
    "    return forecast_growth_adj\n",
    "\n",
    "def get_forecast_hour_adj(hour_adj, date_range):\n",
    "    doy_hour_adj = hour_adj.loc[hour_adj.index.max() - pd.DateOffset(365):]\n",
    "    doy_hour_adj = doy_hour_adj.asfreq('D').ffill()\n",
    "    doy_hour_adj = doy_hour_adj.groupby(doy_hour_adj.index.dayofyear).mean()\n",
    "    doy_hour_adj.loc[366] = doy_hour_adj.loc[365]\n",
    "\n",
    "    forecast_hour_adj = dict()\n",
    "\n",
    "    for hour_date in date_range:\n",
    "        forecast_hour_adj[hour_date] = doy_hour_adj.loc[hour_date.dayofyear, hour_date.hour]\n",
    "\n",
    "    forecast_hour_adj = pd.Series(forecast_hour_adj)\n",
    "\n",
    "    return forecast_hour_adj\n",
    "\n",
    "def get_load_norm(data, coefs, hour_adj):\n",
    "    load_norm = run_load_model(data['temp_norm'], coefs, hour_adj)\n",
    "    forecast_data = data['temp_norm'].loc[load_norm.index.max():]\n",
    "    forecast_data = pd.concat([forecast_data, get_workday(forecast_data)], axis=1)\n",
    "\n",
    "    forecast_load = load_coefs_func(forecast_data, *coefs.loc[coefs.index.max()])\n",
    "    forecast_date_range = forecast_load.index\n",
    "\n",
    "    forecast_growth_adj = get_forecast_growth_adj(data, forecast_date_range)\n",
    "    forecast_hour_adj = get_forecast_hour_adj(hour_adj, forecast_date_range)\n",
    "    forecast_load = forecast_load*forecast_growth_adj*forecast_hour_adj\n",
    "\n",
    "    load_norm = pd.concat([load_norm, forecast_load])\n",
    "    load_norm.name = 'load'\n",
    "    return load_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "iso_rto = 'ERCOT'\n",
    "iso_zone = 'ERCOT'\n",
    "\n",
    "sids_exist, iso_zone_sids = get_iso_zone_sids(iso_rto, iso_zone)\n",
    "if sids_exist:\n",
    "    data = get_data(iso_zone_sids)\n",
    "    coefs = fit_coefs(data)\n",
    "    hour_adj = fit_hour_adj(data, coefs)\n",
    "    load_norm = get_load_norm(data, coefs, hour_adj)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_norm = get_load_norm(data, coefs, hour_adj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2013-06-09 00:00:00    42521.740618\n",
       "2013-06-09 01:00:00    46188.546506\n",
       "2013-06-09 02:00:00    49261.182974\n",
       "2013-06-09 03:00:00    51687.524236\n",
       "2013-06-09 04:00:00    53362.967892\n",
       "                           ...     \n",
       "2030-12-30 20:00:00    54773.422551\n",
       "2030-12-30 21:00:00    55416.339897\n",
       "2030-12-30 22:00:00    56035.543794\n",
       "2030-12-30 23:00:00    55898.850289\n",
       "2030-12-31 00:00:00    54924.840661\n",
       "Name: load, Length: 153938, dtype: float64"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
